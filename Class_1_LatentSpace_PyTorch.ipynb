{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNnFj5gOjmNDDxE6jY1I4ap",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijaygwu/SEAS8525/blob/main/Class_1_LatentSpace_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code defines and utilizes an Autoencoder neural network for the MNIST dataset. Here's a detailed explanation:\n",
        "\n",
        "- **Autoencoder Class**: This class creates a neural network with encoder and decoder components. The encoder compresses the input image into a lower-dimensional latent space, and the decoder reconstructs the image from this latent space. The network is structured to flatten and process 28x28 grayscale MNIST images.\n",
        "\n",
        "- **Data Loading**: Utilizes PyTorch's DataLoader to efficiently load the MNIST dataset, applying transformations to normalize the images.\n",
        "\n",
        "- **Training Loop**: Iterates over the training dataset, feeding batches of images through the model, calculating the reconstruction loss, and updating the model's weights to minimize this loss, effectively learning to compress and reconstruct the input images.\n",
        "\n",
        "- **Visualization**: After training, the script visualizes a batch of original images and their reconstructions from the autoencoder. It also prints the latent space representations, showcasing what the model has learned to encode.\n",
        "\n",
        "- **Utility Functions**: Includes `imshow` for displaying tensors as images. It unnormalizes the data and uses Matplotlib to plot them.\n",
        "\n",
        "This script encapsulates the end-to-end process of training an autoencoder on the MNIST dataset, visualizing the results, and examining the learned latent space."
      ],
      "metadata": {
        "id": "MXble1sY6GuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "from torch.cuda.amp import GradScaler, autocast"
      ],
      "metadata": {
        "id": "QTp8sYxwBg-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, encoding_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Encoder: compresses the image into a lower-dimensional latent space\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),  # Flatten the image and then linearly transform it\n",
        "            nn.ReLU(True),  # Non-linear activation function\n",
        "            nn.Linear(128, encoding_dim),  # Linear transformation to the encoding dimension\n",
        "            nn.ReLU(True)  # Non-linear activation function\n",
        "        )\n",
        "        # Decoder: reconstructs the image from the latent space\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, 128),  # Linearly transforms the encoding\n",
        "            nn.ReLU(True),  # Non-linear activation function\n",
        "            nn.Linear(128, 28 * 28),  # Transforms back to original image shape\n",
        "            nn.Sigmoid()  # Sigmoid activation to output values between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x.view(-1, 28*28))  # Encode the input image\n",
        "        x = self.decoder(x)  # Decode the encoded image\n",
        "        return x.view(-1, 1, 28, 28)  # Reshape to the original image dimensions"
      ],
      "metadata": {
        "id": "wWlX07fEBjL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def imshow(img):\n",
        "    img = img.cpu() / 2 + 0.5  # Unnormalize the image\n",
        "    npimg = img.numpy()  # Convert the tensor to a numpy array\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # Reshape and display the image\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yP7S8PazBoD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform: converts images to PyTorch tensors and normalizes them\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n"
      ],
      "metadata": {
        "id": "yJAgqh0TBrMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset loading\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "cQpswSgnBw4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Autoencoder(encoding_dim=64).to(device)\n",
        "criterion = nn.MSELoss()  # Loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # Optimizer"
      ],
      "metadata": {
        "id": "W8NemtCtB35p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "scaler = GradScaler()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for data in train_loader:\n",
        "        img, _ = data\n",
        "        img = img.to(device)\n",
        "\n",
        "        with autocast():\n",
        "            output = model(img)\n",
        "            loss = criterion(output, img)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "    print('Epoch [{}/{}], Loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRk72snY6LPD",
        "outputId": "b23a61ae-a967-4e90-ad99-ed4d0e063797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss:0.9331\n",
            "Epoch [2/10], Loss:0.9275\n",
            "Epoch [3/10], Loss:0.9337\n",
            "Epoch [4/10], Loss:0.9248\n",
            "Epoch [5/10], Loss:0.9287\n",
            "Epoch [6/10], Loss:0.9207\n",
            "Epoch [7/10], Loss:0.9269\n",
            "Epoch [8/10], Loss:0.9246\n",
            "Epoch [9/10], Loss:0.9296\n",
            "Epoch [10/10], Loss:0.9230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of the original and reconstructed images\n",
        "dataiter = iter(train_loader)\n",
        "images, _ = next(dataiter)\n",
        "images = images.to(device)\n",
        "\n",
        "# Display original images\n",
        "print(\"Original Images\")\n",
        "imshow(vutils.make_grid(images[:4], normalize=True))\n",
        "\n",
        "# Encoded and decoded images\n",
        "with torch.no_grad():\n",
        "    encoded_imgs = model.encoder(images.view(-1, 28*28)[:4])\n",
        "    decoded_imgs = model.decoder(encoded_imgs).view(-1, 1, 28, 28)\n",
        "\n",
        "# Display reconstructed images\n",
        "#print(\"Reconstructed Images\")\n",
        "#imshow(vutils.make_grid(decoded_imgs, normalize=True))\n",
        "\n",
        "# Display reconstructed images\n",
        "print(\"Original Representation\")\n",
        "print(img)\n",
        "\n",
        "# Print latent space\n",
        "print(\"Latent space representations:\")\n",
        "print(encoded_imgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FCsJeFk2B2Fi",
        "outputId": "4f06809f-76e4-4fa5-face-99694575687f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Representation\n",
            "tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
            "\n",
            "\n",
            "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
            "\n",
            "\n",
            "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
            "\n",
            "\n",
            "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
            "\n",
            "\n",
            "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]]]], device='cuda:0')\n",
            "Latent space representations:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  9.4540, 14.5894,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         26.6025,  0.0000, 55.4785,  7.7348,  0.0000, 20.7195,  0.0000,  0.0000,\n",
            "          4.0518,  0.0000, 28.9647,  7.3773,  0.0000,  0.0000,  0.0000,  2.8713,\n",
            "         15.6097,  0.0000, 42.7976,  0.0000, 16.6456, 22.6829,  0.0000, 33.5873,\n",
            "          2.6367, 18.6450,  0.0000,  4.8683,  0.0000,  0.0000, 31.3724,  0.0000,\n",
            "          0.0000, 49.5516,  0.0000,  0.0000,  0.0000,  0.0000, 12.1242,  0.0000,\n",
            "          0.0000, 30.6223, 27.7208,  0.0000, 50.3909,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  9.5517, 14.6817,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         25.4762,  0.0000, 54.0132,  7.5951,  0.0000, 19.7938,  0.0000,  0.0000,\n",
            "          3.7761,  0.0000, 28.7268,  7.4963,  0.0000,  0.0000,  0.0000,  3.2697,\n",
            "         15.2527,  0.0000, 41.7064,  0.0000, 16.2959, 22.1286,  0.0000, 33.0386,\n",
            "          2.7551, 18.0216,  0.0000,  5.2235,  0.0000,  0.0000, 30.7087,  0.0000,\n",
            "          0.0000, 48.1693,  0.0000,  0.0000,  0.0000,  0.0000, 11.7373,  0.0000,\n",
            "          0.0000, 30.7551, 27.0926,  0.0000, 49.2535,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000, 10.6180, 16.3836,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         29.8774,  0.0000, 62.7203,  8.8521,  0.0000, 23.0540,  0.0000,  0.0000,\n",
            "          4.3544,  0.0000, 32.5358,  8.5367,  0.0000,  0.0000,  0.0000,  3.3088,\n",
            "         17.5134,  0.0000, 47.7280,  0.0000, 18.9506, 25.5438,  0.0000, 37.5455,\n",
            "          2.7619, 20.7516,  0.0000,  5.0911,  0.0000,  0.0000, 35.5638,  0.0000,\n",
            "          0.0000, 55.9722,  0.0000,  0.0000,  0.0000,  0.0000, 13.5877,  0.0000,\n",
            "          0.0000, 34.7844, 31.1956,  0.0000, 57.0178,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  8.9707, 14.1570,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         25.6757,  0.0000, 53.6851,  7.5324,  0.0000, 19.9014,  0.0000,  0.0000,\n",
            "          3.9907,  0.0000, 28.2078,  7.2998,  0.0000,  0.0000,  0.0000,  3.0858,\n",
            "         15.3330,  0.0000, 41.0269,  0.0000, 16.1051, 22.0139,  0.0000, 32.3278,\n",
            "          2.7340, 17.8436,  0.0000,  4.5794,  0.0000,  0.0000, 30.4675,  0.0000,\n",
            "          0.0000, 48.0335,  0.0000,  0.0000,  0.0000,  0.0000, 11.7625,  0.0000,\n",
            "          0.0000, 29.8211, 26.8709,  0.0000, 48.5930,  0.0000,  0.0000,  0.0000]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}